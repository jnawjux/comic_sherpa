{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (pyspark.sql.SparkSession.builder\n",
    "    .master(\"local\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading comic and movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_reviews = spark.read.json('data/all_comic_reviews_in_mtv.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = spark.read.json('data/all_movietv_jsons/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------+\n",
      "|      asin|overall|          reviewText|    reviewerID|\n",
      "+----------+-------+--------------------+--------------+\n",
      "|0316107255|    4.0|PENGUIN DREAMS AN...|A3NQU1649SH0Q4|\n",
      "+----------+-------+--------------------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comic_reviews.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new ids\n",
    "Since the Amazon user and item ids contain both letters and numbers, I needed to give them new values for a couple reasons:\n",
    "* The Spark ALS model will only take labels that are numeric and will cause an error otherwise.\n",
    "* I can create ids for the comic books and movies/tv that are easily identifiable and easy to filter on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_id_dictionary(df, column, suffix_val):\n",
    "    \"\"\"Take in column with unique indexes, return dictionary with new index values. This is done to\n",
    "     remove the default ASIN and user ID from Amazon reviews and create better unique ids.\n",
    "    Args:\n",
    "        df: source dataframe\n",
    "        column: name of column with ids to replace\n",
    "        suffix_val: new suffix value for unique codes. Example: all new user_ids could end\n",
    "        with '00000'\n",
    "    Returns:\n",
    "        new_id_dict: New Spark dataframe with column of new unique ids\n",
    "    \n",
    "    \"\"\"\n",
    "    unique_vals = list(set([old_id[0] for old_id in df.select(column).collect()]))\n",
    "    new_ids = [(str(i) + suffix_val) for i in range(1,len(unique_vals)+1)]\n",
    "    new_id_dict = {k:v for k,v in zip(unique_vals, new_ids)}\n",
    "    return new_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ids = new_id_dictionary(comic_reviews, 'reviewerID', '0000')\n",
    "new_comic_asins = new_id_dictionary(comic_reviews, 'asin', '2222')\n",
    "new_mtv_asins = new_id_dictionary(movie_reviews, 'asin', '4444')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_asins = new_comic_asins\n",
    "all_items_asins = all_items_asins.update(new_mtv_asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_id(old_id, new_id_dict):\n",
    "    new_id = id_dict[old_id]\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "udfUserId = F.udf(lambda x: new_user_ids[x], StringType())\n",
    "\n",
    "udfComicId = F.udf(lambda x: new_comic_asins[x], StringType())\n",
    "udfMovieId = F.udf(lambda x: new_mtv_asins[x], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_reviews_updated = comic_reviews.withColumn(\"item_id\", udfComicId(\"asin\"))\n",
    "comic_reviews_updated = comic_reviews_updated.withColumn(\"user_id\", udfUserId(\"reviewerID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_r_final = comic_reviews_updated.select(['user_id','item_id', 'overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+\n",
      "| user_id| item_id|overall|\n",
      "+--------+--------+-------+\n",
      "|11920000|49362222|    4.0|\n",
      "+--------+--------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comic_r_final.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_updated = movie_reviews.withColumn(\"user_id\", udfUserId(\"reviewerID\"))\n",
    "movie_reviews_updated_2 = movie_reviews_updated.withColumn(\"item_id\", udfMovieId(\"asin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_r_final = movie_reviews_updated_2.select(['user_id', 'item_id', 'overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "| user_id|  item_id|overall|\n",
      "+--------+---------+-------+\n",
      "|93150000|259104444|    4.0|\n",
      "+--------+---------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_r_final.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrowing my dataset\n",
    "To help improve the accuracy of my model, I wanted to look through removing some of the items and users that may not offer much insight because of their sparsity. Here I explored some of these features to help me decide on what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing users who have rated less than average in either comics or movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    item_id \n",
    ",   COUNT(*) as count \n",
    "FROM \n",
    "    table \n",
    "GROUP BY item_id\n",
    "ORDER BY count desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_r_final.createOrReplaceTempView('table')\n",
    "comic_low_reviewers = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of items with less than average amount of comic reviews: 4113\n"
     ]
    }
   ],
   "source": [
    "low_reviews = comic_low_reviewers[comic_low_reviewers['count'] \\\n",
    "                                  <= comic_low_reviewers['count'].mean()]\n",
    "print(f\"Amount of items with less than average amount of comic reviews: {low_reviews.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_r_final.createOrReplaceTempView('table')\n",
    "mtv_low_reviewers = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of items with less than average amount of comic reviews: 33977\n"
     ]
    }
   ],
   "source": [
    "low_mtv_reviews = mtv_low_reviewers[mtv_low_reviewers['count'] \\\n",
    "                                  <= mtv_low_reviewers['count'].mean()]\n",
    "print(f\"Amount of items with less than average amount of comic reviews: {low_mtv_reviews.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_item = list(set(low_reviews['item_id'].tolist() + low_mtv_reviews['item_id'].tolist()))\n",
    "len(low_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = comic_r_final.union(movies_r_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rev_ready = all_reviews.filter(F.col('item_id').isin(low_user) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179817"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rev_ready.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_ready = all_rev_ready.select([col(\"user_id\").cast(IntegerType()),\\\n",
    "                                  col(\"item_id\").cast(IntegerType()),\\\n",
    "                                  col(\"overall\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, item_id: int, overall: double]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_ready.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = als_ready.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS\n",
    "als = ALS(userCol='user_id', itemCol='item_id', ratingCol='overall', nonnegative=True)\n",
    "\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = als_model.transform(train)\n",
    "test_pred = als_model.transform(test)\n",
    "train_pred_dropna = train_pred.dropna()\n",
    "test_pred_dropna = test_pred.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.3527473004287336\n",
      "Test RMSE: 1.2474849713824216\n",
      "Train MAE: 0.234743665326749\n",
      "Test MAE: 0.9672643011355103\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"overall\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "evaluator_2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"overall\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse_train = evaluator.evaluate(train_pred_dropna)\n",
    "rmse_test = evaluator.evaluate(test_pred_dropna)\n",
    "mae_train = evaluator_2.evaluate(train_pred_dropna)\n",
    "mae_test = evaluator_2.evaluate(test_pred_dropna)\n",
    "print(f\"Train RMSE: {rmse_train}\")\n",
    "print(f\"Test RMSE: {rmse_test}\")\n",
    "print(f\"Train MAE: {mae_train}\")\n",
    "print(f\"Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----------+\n",
      "|  user_id| item_id|overall| prediction|\n",
      "+---------+--------+-------+-----------+\n",
      "| 81990000| 2922222|    4.0|   3.611361|\n",
      "| 68200000| 9762222|    5.0|   4.811065|\n",
      "|101710000| 9762222|    5.0|  5.4884887|\n",
      "| 22760000| 9762222|    5.0|  4.9215364|\n",
      "| 41760000| 9762222|    5.0|   4.251208|\n",
      "|100510000|10374444|    2.0|  1.7457337|\n",
      "| 79080000|10374444|    3.0|0.015979275|\n",
      "| 52380000|11934444|    4.0|  3.1411307|\n",
      "| 26730000|11934444|    3.0|  3.4213014|\n",
      "| 68070000|11934444|    5.0|  3.5709882|\n",
      "+---------+--------+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-e1a18bc29bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## instantiating crossvalidator estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "als = ALS(userCol='user_id', itemCol='item_id', ratingCol='overall', nonnegative=True)\n",
    "\n",
    "reg_test = RegressionEvaluator(predictionCol='prediction', labelCol='overall')\n",
    "\n",
    "# create the parameter grid              \n",
    "params = ParamGridBuilder().addGrid(als.regParam, [0.01,0.001,0.1])\\\n",
    "                           .addGrid(als.rank, [4,10,50])\n",
    "                           .addGrid(als.maxIter, [5,10,15,20]).build()\n",
    "             \n",
    "## instantiating crossvalidator estimator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=params,evaluator=reg_test,parallelism=4)\n",
    "best_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = als_ready.select(als.getUserCol()).distinct().limit(5)\n",
    "userSubsetRecs = als_model.recommendForUserSubset(users, 50).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o78473.recommendForUserSubset. Trace:\npy4j.Py4JException: Method recommendForUserSubset([class java.lang.Integer, class java.lang.Integer]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-a6ef3d3d89f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_fella\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendForUserSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m59720000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/ml/recommendation.py\u001b[0m in \u001b[0;36mrecommendForUserSubset\u001b[0;34m(self, dataset, numItems)\u001b[0m\n\u001b[1;32m    438\u001b[0m                  \u001b[0mstored\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitemCol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mRows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \"\"\"\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recommendForUserSubset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumItems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.3.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o78473.recommendForUserSubset. Trace:\npy4j.Py4JException: Method recommendForUserSubset([class java.lang.Integer, class java.lang.Integer]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
     ]
    }
   ],
   "source": [
    "one_fella = als_model.recommendForUserSubset(59720000, 50).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = als_model.recommendForAllUsers(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41640000</td>\n",
       "      <td>[(202884444, 5.505423545837402), (85914444, 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55810000</td>\n",
       "      <td>[(176574444, 5.911088943481445), (224904444, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59720000</td>\n",
       "      <td>[(202884444, 6.963602542877197), (113704444, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100310000</td>\n",
       "      <td>[(202884444, 4.817611217498779), (183424444, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102120000</td>\n",
       "      <td>[(132014444, 5.877918243408203), (202474444, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                    recommendations\n",
       "0   41640000  [(202884444, 5.505423545837402), (85914444, 5....\n",
       "1   55810000  [(176574444, 5.911088943481445), (224904444, 5...\n",
       "2   59720000  [(202884444, 6.963602542877197), (113704444, 6...\n",
       "3  100310000  [(202884444, 4.817611217498779), (183424444, 4...\n",
       "4  102120000  [(132014444, 5.877918243408203), (202474444, 5..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userSubsetRecs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_comic_recommendations(user_id):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comic_recommendations(user_id):\n",
    "    recs_for_user = recommendations.where(recommendations.user_id == user_id).take(1)\n",
    "    all_recs = [i[0] for i in recs_for_user[0][1]]\n",
    "    all_comic_recs = [i for i in all_recs if str(i).endswith('22') == True]\n",
    "    for rec in all_comic_recs:\n",
    "        query_reviews = f\"\"\"\n",
    "                        SELECT\n",
    "                            asin\n",
    "                        FROM \n",
    "                            table\n",
    "                        WHERE item_id == {rec}\"\"\" \n",
    "        comic_reviews_updated.createOrReplaceTempView('table')\n",
    "        temp_df = spark.sql(query_reviews).toPandas()\n",
    "        asin = temp_df.loc[0]['asin']\n",
    "        print(comic_names.loc[comic_names['asin'] == asin, 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1557    Astro City Shining Stars (Kurt Busiek's Astro ...\n",
      "Name: title, dtype: object\n",
      "413    The Legend of Luther Strode Volume 2 TP\n",
      "Name: title, dtype: object\n",
      "1160    Amazing Fantasy Omnibus (v. 1)\n",
      "Name: title, dtype: object\n",
      "285    Fables: The Deluxe Edition Book Eight\n",
      "Name: title, dtype: object\n",
      "2022    Incredible Hulk: Planet Skaar\n",
      "Name: title, dtype: object\n",
      "661    Marvel Masterworks: Incredible Hulk - Volume 2\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "get_comic_recommendations(59720000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_names = pd.read_csv('data/all_comic_asin.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_reviews = f\"\"\"\n",
    "SELECT\n",
    "    asin\n",
    "FROM \n",
    "    table\n",
    "WHERE item_id == {value}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_reviews_als.createOrReplaceTempView('table')\n",
    "temp_user_view = spark.sql(query_reviews).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9240000</td>\n",
       "      <td>35952222</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9240000</td>\n",
       "      <td>345724444</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    item_id  overall\n",
       "0  9240000   35952222      5.0\n",
       "1  9240000  345724444      4.0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_user_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed = temp_user_view.item_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewed & recomended\n",
    "recommended_asin = [key for key, val in new_comic_asins.items() if int(val) in comic_user_test]\n",
    "reviewed_asin = [key for key, val in new_comic_asins.items() if int(val) in reviewed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292                                   Fables Encyclopedia\n",
       "279     Thor Visionaries - Walt Simonson, Vol. 2 (Marv...\n",
       "553     Essential Tomb of Dracula, Vol. 3 (Marvel Esse...\n",
       "1247                      Ultimate Fantastic Four, Vol. 3\n",
       "2975                   Black Widow: The Itsy-Bitsy Spider\n",
       "3064                          Deadpool Classic - Volume 6\n",
       "3567    S.H.I.E.L.D. by Jim Steranko: The Complete Col...\n",
       "78                                                 Empire\n",
       "516                            Penguin Revolution: VOL 02\n",
       "669                          Penguin Revolution: Volume 3\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comic_names = pd.read_csv('data/all_comic_asin.csv', index_col=0)\n",
    "comic_names.loc[comic_names['asin'].isin(recommended_asin), 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147    Amazing Spider-Man Omnibus, Vol. 1 (v. 1)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comic_names.loc[comic_names['asin'].isin(reviewed_asin), 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_recs(user_id,new_ratings,rating_df,movie_title_df,num_recs):\n",
    "    # turn the new_recommendations list into a spark DataFrame\n",
    "    new_user_ratings = spark.createDataFrame(new_ratings,rating_df.columns)\n",
    "    \n",
    "    # combine the new ratings df with the rating_df\n",
    "    movie_ratings_combined = rating_df.union(new_user_ratings)\n",
    "    \n",
    "    # split the dataframe into a train and test set\n",
    "#     (training, test) = movie_ratings_combined.randomSplit([0.8, 0.2],seed=0)\n",
    "    \n",
    "    # create an ALS model and fit it\n",
    "    als = ALS(maxIter=5,rank=50, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "    model = als.fit(movie_ratings_combined)\n",
    "    \n",
    "    # make recommendations for all users using the recommendForAllUsers method\n",
    "    recommendations = model.recommendForAllUsers(num_recs)\n",
    "    \n",
    "    # get recommendations specifically for the new user that has been added to the DataFrame\n",
    "    recs_for_user = recommendations.where(recommendations.userId == user_id).take(1)\n",
    "    \n",
    "    for ranking, (movie_id, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
    "        movie_string = name_retriever(movie_id,movie_title_df)\n",
    "        print('Recommendation {}: {}  | predicted score :{}'.format(ranking+1,movie_string,rating))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
