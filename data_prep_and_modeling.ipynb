{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from batcave.scrape_and_clean import new_id_dictionary, get_missing_titles\n",
    "from batcave.recommend import get_recommendations_testing, get_user_reviews_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (pyspark.sql.SparkSession.builder\n",
    "    .master(\"local\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading comic and movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_reviews = spark.read.json('data/comic_reviews_wtitle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = spark.read.json('data/movie_reviews_wtitle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+--------------+--------------------+\n",
      "|      asin|               imUrl|overall|    reviewerID|               title|\n",
      "+----------+--------------------+-------+--------------+--------------------+\n",
      "|0345507460|http://ecx.images...|    5.0| ACO26JQ366659|The Dresden Files...|\n",
      "|0345507460|http://ecx.images...|    5.0|A34C35QFA4DC5J|The Dresden Files...|\n",
      "|0345507460|http://ecx.images...|    5.0|A3TII4RKU0ZVT4|The Dresden Files...|\n",
      "|0345507460|http://ecx.images...|    5.0|A1LR4Z5Z0MPYIF|The Dresden Files...|\n",
      "|0345507460|http://ecx.images...|    5.0|A16L43DIFSHGMQ|The Dresden Files...|\n",
      "+----------+--------------------+-------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comic_reviews.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new ids\n",
    "Since the Amazon user and item ids contain both letters and numbers, I needed to give them new values for a couple reasons:\n",
    "* The Spark ALS model will only take labels that are numeric and will cause an error otherwise.\n",
    "* I can create ids for the comic books and movies/tv that are easily identifiable and easy to filter on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ids = new_id_dictionary(comic_reviews, 'reviewerID', '00')\n",
    "new_comic_asins = new_id_dictionary(comic_reviews, 'asin', '22')\n",
    "new_mtv_asins = new_id_dictionary(movie_reviews, 'asin', '44')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_asins = new_comic_asins\n",
    "all_items_asins.update(new_mtv_asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "udfUserId = F.udf(lambda x: new_user_ids[x], StringType())\n",
    "udfItemId = F.udf(lambda x: all_items_asins[x], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_reviews_updated = comic_reviews.withColumn(\"item_id\", udfItemId(\"asin\"))\n",
    "comic_reviews_updated = comic_reviews_updated.withColumn(\"user_id\", udfUserId(\"reviewerID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "|      asin|               imUrl|overall|   reviewerID|               title|item_id|user_id|\n",
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "|0345507460|http://ecx.images...|    5.0|ACO26JQ366659|The Dresden Files...| 509122| 125700|\n",
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comic_reviews_updated.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_updated = movie_reviews.withColumn(\"item_id\", udfItemId(\"asin\"))\n",
    "movie_reviews_updated = movie_reviews_updated.withColumn(\"user_id\", udfUserId(\"reviewerID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "|      asin|               imUrl|overall|   reviewerID|               title|item_id|user_id|\n",
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "|0767807693|http://ecx.images...|    3.0|ADENUJJYKNHPO|Requiem for a Hea...|2707744| 215000|\n",
      "+----------+--------------------+-------+-------------+--------------------+-------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_reviews_updated.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrowing my dataset\n",
    "To help improve the accuracy of my model, I wanted to look through removing some of the items and users that may not offer much insight because of their sparsity. Here I explored some of these features to help me decide on what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing users who have rated less than average in either comics or movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    item_id \n",
    ",   COUNT(*) as count \n",
    "FROM \n",
    "    table \n",
    "GROUP BY item_id\n",
    "ORDER BY count desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic_reviews_updated.createOrReplaceTempView('table')\n",
    "comic_low_reviewers = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of items with less than average amount of comic reviews: 4129\n"
     ]
    }
   ],
   "source": [
    "low_reviews = comic_low_reviewers[comic_low_reviewers['count'] \\\n",
    "                                  <= comic_low_reviewers['count'].mean()]\n",
    "print(f\"Amount of items with less than average amount of comic reviews: {low_reviews.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_updated.createOrReplaceTempView('table')\n",
    "mtv_low_reviewers = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of items with less than average amount of movie reviews: 26036\n"
     ]
    }
   ],
   "source": [
    "low_mtv_reviews = mtv_low_reviewers[mtv_low_reviewers['count'] \\\n",
    "                                  <= mtv_low_reviewers['count'].mean()]\n",
    "print(f\"Amount of items with less than average amount of movie reviews: {low_mtv_reviews.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234044</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>579744</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900344</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531144</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902244</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  count\n",
       "0   234044    170\n",
       "1   579744    163\n",
       "2  1900344    141\n",
       "3   531144    140\n",
       "4   902244    133"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtv_low_reviewers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30165"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_item = list(set(low_reviews['item_id'].tolist() + low_mtv_reviews['item_id'].tolist()))\n",
    "len(low_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining and adding review counts\n",
    "all_review_counts_df = pd.concat([mtv_low_reviewers,comic_low_reviewers])\n",
    "all_review_counts = spark.createDataFrame(all_review_counts_df)\n",
    "\n",
    "# Joining comic & movie data\n",
    "all_reviews = comic_reviews_updated.union(movie_reviews_updated)\n",
    "\n",
    "# Adding the count column\n",
    "all_reviews = all_reviews.join(all_review_counts, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+-------+--------------+--------------------+-------+-----+\n",
      "|item_id|      asin|               imUrl|overall|    reviewerID|               title|user_id|count|\n",
      "+-------+----------+--------------------+-------+--------------+--------------------+-------+-----+\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    1.0| A9XKE4OE48BNK|Doctor Who - The ...| 460400|    6|\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    4.0| AN9J46667D80O|Doctor Who - The ...| 450600|    6|\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    5.0|A2P49WD75WHAG5|Doctor Who - The ...| 564200|    6|\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    3.0| A9ZAL2YHXSMFF|Doctor Who - The ...| 805400|    6|\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    4.0|A27P0MW8TE1JQP|Doctor Who - The ...| 384700|    6|\n",
      "|1003644|B0000ADXG8|http://ecx.images...|    4.0|A3TRXPRUYVOLSM|Doctor Who - The ...| 859500|    6|\n",
      "| 101122|1401219349|http://ecx.images...|    2.0|A1ZAJCZHFV7OZD|Superman: Past an...| 314300|    1|\n",
      "|1027644|B003BUAOZ2|http://ecx.images...|    4.0|A329U9CDUPKXAC|                null| 277400|    1|\n",
      "|1028644|B0034G4P1C|http://ecx.images...|    5.0| AWG2O9C42XW5G|                null| 276900|    1|\n",
      "| 102944|B000E0OE76|http://ecx.images...|    3.0|A2RKI7RPP5CJMG|           Headspace| 471100|    3|\n",
      "+-------+----------+--------------------+-------+--------------+--------------------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_ready = all_reviews.filter(F.col('item_id').isin(low_item) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-------+----------+-----+-------+-----+\n",
      "|item_id|asin|imUrl|overall|reviewerID|title|user_id|count|\n",
      "+-------+----+-----+-------+----------+-----+-------+-----+\n",
      "|   7521|7521| 7361|      5|      8545| 5293|   8545|  105|\n",
      "+-------+----+-----+-------+----------+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seeing the unique count of users and items\n",
    "all_reviews_ready.agg(*(F.countDistinct(col(c)).alias(c) for c in all_reviews_ready.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to temporarily preserve\n",
    "all_reviews_ready.repartition(1).write.json(\"data/all_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case of the missing titles\n",
    "Even though I had limited my set to movies/tv that have metadata, I found that some of the metadata is missing the title for movies, which is a pretty important piece for my further development!  Since I do have the ASINs, I wrote a quick function to find those missing titles by querying Amazon and then returning the first only results title. My process was as follows:\n",
    "* Get the ASINs for data missing titles\n",
    "* Run function on those ASINs to return a title\n",
    "* Do some clean up of titles\n",
    "* Add titles back to original data and drop old listing\n",
    "* Export all_reviews again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = spark.read.json('data/all_reviews.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the ASINS from products missing titles\n",
    "missing_titles = all_reviews.select(['asin','title']).toPandas()\n",
    "\n",
    "missing_asins = list(set(missing_titles.loc[missing_titles['title'].isna(), 'asin'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Records missing name: 2205\n"
     ]
    }
   ],
   "source": [
    "print(f\" Records missing name: {len(missing_asins)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a function to scrape Amazon for the title - Takes a few hours to complete\n",
    "missing_title_info = get_missing_titles(missing_asins[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these into a dataframe to inspect\n",
    "missing_df = pd.DataFrame(missing_title_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df.to_csv('data/missing_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.read_csv('data/missing_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still had some that returned no name, so ignoring for now and will drop from all reviews\n",
    "all_the_good = missing_df[missing_df['title'] != 'None found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0023BZ65S</th>\n",
       "      <td>0</td>\n",
       "      <td>Big Man Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00404ME2E</th>\n",
       "      <td>1</td>\n",
       "      <td>Space Precinct 2040: The Complete Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000WZEZFY</th>\n",
       "      <td>3</td>\n",
       "      <td>Superbad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B009VL28W2</th>\n",
       "      <td>4</td>\n",
       "      <td>Quebec Magnetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00BN3ED8I</th>\n",
       "      <td>5</td>\n",
       "      <td>Movie 43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0                                     title\n",
       "asin                                                            \n",
       "B0023BZ65S           0                             Big Man Japan\n",
       "B00404ME2E           1  Space Precinct 2040: The Complete Series\n",
       "B000WZEZFY           3                                  Superbad\n",
       "B009VL28W2           4                           Quebec Magnetic\n",
       "B00BN3ED8I           5                                  Movie 43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting ASIN as index to do replace with original set\n",
    "all_the_good.set_index('asin', inplace=True)\n",
    "missing_titles.set_index('asin', inplace=True)\n",
    "all_the_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining to replace missing titles\n",
    "missing_titles = missing_titles.combine_first(all_the_good)\n",
    "\n",
    "# Resetting the index and changing title column name \n",
    "missing_titles.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of all without a title still\n",
    "check_missing_asins = list(set(missing_df.loc[missing_titles['title'].isna(), 'asin'].tolist()))\n",
    "\n",
    "# Dropping rows with reviews that have no title from original dataframe\n",
    "all_reviews_less_missing_titles = all_reviews.filter(F.col('asin').isin(check_missing_asins)==False)\n",
    "\n",
    "# Dropping rows from my temporary dataframe with correct names\n",
    "fix_titles = missing_titles.drop(missing_titles[missing_titles['title'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some text cleanup on titles. There may be more later, but these are the initial examples I found:\n",
    "potential_regs = \"\"\"\\[VHS\\]|\\[DVD\\]|Collector\\'s Edition|\\: Season \\d+\n",
    "                    |\\: The Complete Series|\\: Complete Series|\\(.*\\)\"\"\"\n",
    "\n",
    "fix_titles['title'] = fix_titles['title']\\\n",
    "                         .apply(lambda x: re.sub(potential_regs, '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005119367</td>\n",
       "      <td>Joseph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005119367</td>\n",
       "      <td>Joseph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005119367</td>\n",
       "      <td>Joseph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005119367</td>\n",
       "      <td>Joseph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0307142469</td>\n",
       "      <td>Frosty the Snowman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                title\n",
       "0  0005119367              Joseph \n",
       "1  0005119367              Joseph \n",
       "2  0005119367              Joseph \n",
       "3  0005119367              Joseph \n",
       "4  0307142469  Frosty the Snowman "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_titles.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "fix_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark dataframe from dataframe with corrected titles\n",
    "fixed_titles_spark = spark.createDataFrame(fix_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining & exporting\n",
    "all_reviews_no_title = all_reviews_less_missing_titles.select(['asin',\n",
    "                                                               'count',\n",
    "                                                               'imUrl',\n",
    "                                                               'item_id',\n",
    "                                                               'overall',\n",
    "                                                               'reviewerID',\n",
    "                                                               'user_id'])\n",
    "\n",
    "all_reviews_with_fixed_titles = all_reviews_no_title.join(fixed_titles_spark,\n",
    "                                                                     on='asin',\n",
    "                                                                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+-------+-------+-------------+-------+--------------------+\n",
      "|      asin|count|               imUrl|item_id|overall|   reviewerID|user_id|               title|\n",
      "+----------+-----+--------------------+-------+-------+-------------+-------+--------------------+\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "|0345507460|   57|http://ecx.images...| 509122|    5.0|ACO26JQ366659| 125700|The Dresden Files...|\n",
      "+----------+-----+--------------------+-------+-------+-------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_reviews_with_fixed_titles.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_with_fixed_titles.repartition(1).write.json('data/all_reviews_corrections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews  = spark.read.json('data/all_reviews_fixed_titles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[asin: string, count: bigint, imUrl: string, item_id: bigint, overall: double, reviewerID: string, title: string, user_id: bigint]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_ready = all_reviews.select([F.col(\"user_id\").cast(IntegerType()),\n",
    "                                  F.col(\"item_id\").cast(IntegerType()),\n",
    "                                  F.col(\"overall\"), F.col(\"title\"), F.col(\"imUrl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = als_ready.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS\n",
    "als = ALS(rank=50, regParam=.1, maxIter=20,\n",
    "          userCol='user_id', itemCol='item_id', \n",
    "          ratingCol='overall', nonnegative=True)\n",
    "\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for test split\n",
    "test_pred = als_model.transform(test)\n",
    "\n",
    "# Filling in NaN values with average score\n",
    "test_pred_df = test_pred.toPandas()\n",
    "test_pred_df['prediction'].fillna(4, inplace=True)\n",
    "test_pred = spark.createDataFrame(test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1901424511885796\n",
      "Test MAE: 0.9451618176437001\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"overall\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "evaluator_2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"overall\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(test_pred)\n",
    "mae_test = evaluator_2.evaluate(test_pred)\n",
    "print(f\"Test RMSE: {rmse_test}\")\n",
    "print(f\"Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning for optimization\n",
    "I kept running into errors with my parameter grid to cross validate below, so ran several tests as well varying parameters and landed on my best model using the configuration found in the above model test.  Below is an example of the parameters this was based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol='user_id', itemCol='item_id', ratingCol='overall', nonnegative=True)\n",
    "\n",
    "reg_test = RegressionEvaluator(predictionCol='prediction', labelCol='overall')\n",
    "\n",
    "# Parameter grid              \n",
    "params = ParamGridBuilder().addGrid(als.regParam, [0.01,0.001,0.1])\\\n",
    "                           .addGrid(als.rank, [4,10,50])\\\n",
    "                           .addGrid(als.maxIter, [5,10,15,20]).build()\n",
    "             \n",
    "## Calling and checking evaluator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=params,evaluator=reg_test,parallelism=4)\n",
    "best_model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning recommendations\n",
    "Below is an example of the two functions created to perform the recommendation operation, just on the Notebook level:\n",
    "* ```get_user_reviews```: gives an individual a selection of movies to choose from within the top 500 most frequently rated movies. Once they have rated at least 10, it creates and returns a dataframe with their score.\n",
    "* ```get_recommedations```: returns the top 4 comic books recommended to the user based on their input.\n",
    "\n",
    "These functions will be used as the basis for creating a functional web application for users to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = get_user_reviews_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>overall</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21044</td>\n",
       "      <td>3</td>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3207644</td>\n",
       "      <td>3</td>\n",
       "      <td>Blazing Saddles</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2908744</td>\n",
       "      <td>3</td>\n",
       "      <td>A Nightmare on Elm Street</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1361144</td>\n",
       "      <td>3</td>\n",
       "      <td>Dark Crystal</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1514044</td>\n",
       "      <td>4</td>\n",
       "      <td>Shrek</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>296644</td>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop Complete Sessions Collection</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2959944</td>\n",
       "      <td>2</td>\n",
       "      <td>Lara Croft: Tomb Raider</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1733544</td>\n",
       "      <td>3</td>\n",
       "      <td>Batman Beyond - Return of the Joker</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>820144</td>\n",
       "      <td>2</td>\n",
       "      <td>Paul</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154644</td>\n",
       "      <td>4</td>\n",
       "      <td>The Texas Chainsaw Massacre</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  overall                                       title  user_id\n",
       "0    21044        3                     It's a Wonderful Life        101\n",
       "1  3207644        3                             Blazing Saddles      101\n",
       "2  2908744        3                   A Nightmare on Elm Street      101\n",
       "3  1361144        3                               Dark Crystal       101\n",
       "4  1514044        4                                     Shrek        101\n",
       "5   296644        1  Cowboy Bebop Complete Sessions Collection       101\n",
       "6  2959944        2                    Lara Croft: Tomb Raider       101\n",
       "7  1733544        3        Batman Beyond - Return of the Joker       101\n",
       "8   820144        2                                        Paul      101\n",
       "9   154644        4                 The Texas Chainsaw Massacre      101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(item_id=45722, title='Thunderbolts: Justice Like Lightning TPB')\n",
      "Row(item_id=63522, title='King City')\n",
      "Row(item_id=506322, title=\"Trick 'r Treat\")\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_testing(user_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! This finishes my data prep and modeling phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
